python -m llama_cpp.server --model ../models/mistral-7b-openorca.Q5_K_M.gguf --n_gpu_layers 1 --port 8081 --chat_format chatml